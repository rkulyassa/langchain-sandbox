{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_url = getpass.getpass(\"Qdrant url: \")\n",
    "qdrant_api_key = getpass.getpass(\"Qdrant API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(url=qdrant_url, api_key=qdrant_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "client.create_collection(\n",
    "    \"langchain-py-rag-pt1-QA\",\n",
    "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "vector_store = QdrantVectorStore(client, collection_name=\"langchain-py-rag-pt1\", embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU beautifulsoup4 langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Total characters: 43884\n"
     ]
    }
   ],
   "source": [
    "# from bs4 import SoupStrainer\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# strainer = SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 68 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "splits = splitter.split_documents(docs);\n",
    "\n",
    "print(f\"Split blog post into {len(splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e3eab4a676874e51a932ab2aab643f4e', 'd818f8e534ff48cbb04ece5e28bd513c', 'b85930e042ed46778b64d1d0eecf338a']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: (question goes here) \\nContext: (context goes here) \\nAnswer:\", additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "print(example_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing import List, TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(query=state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'start_index': 2717, '_id': '451dd672-4c20-48de-a70b-e0b333aac056', '_collection_name': 'langchain-py-rag-pt1'}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'start_index': 2110, '_id': 'f878d41c-4cff-4621-aea1-ff5c8fab2fad', '_collection_name': 'langchain-py-rag-pt1'}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'start_index': 18328, '_id': '03a15d26-fbf2-45ef-83f1-ce4b9af95d98', '_collection_name': 'langchain-py-rag-pt1'}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'start_index': 17938, '_id': 'b0e21d6b-8aeb-4498-87b4-7db0e8d4964a', '_collection_name': 'langchain-py-rag-pt1'}, page_content='Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:')]\n",
      "\n",
      "\n",
      "Answer: Task decomposition is the process of breaking down a complex task into smaller, manageable steps or subgoals. This can be achieved through various methods, including prompting large language models (LLMs) to think step by step, providing task-specific instructions, or utilizing human inputs. The goal is to simplify the task execution and facilitate better performance by addressing each component individually.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')\n",
    "\n",
    "# for step in graph.stream(\n",
    "#     {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "# ):\n",
    "#     print(f\"{step}\\n\\n----------------\\n\")\n",
    "\n",
    "# for message, metadata in graph.stream(\n",
    "#     {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "# ):\n",
    "#     print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[\"context\"])\n",
    "result[\"context\"][0].metadata[\"description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'title': \"LLM Powered Autonomous Agents | Lil'Log\",\n",
       " 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.',\n",
       " 'language': 'en',\n",
       " 'start_index': 6,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third = len(splits) // 3\n",
    "\n",
    "for i, document in enumerate(splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2cd4329034304dd3b96478599dcc643f',\n",
       " 'a1149c9ec21141de80dc31017ae27e25',\n",
       " '7b2848b709dc4aadb5d56a7cd409286d',\n",
       " '96ba7cdf93ca4bc7a64fc539f5ff4999',\n",
       " 'aa15b74303fc43539314ef86c616adae',\n",
       " 'e1f91f33372b49edab7366d7fc801852',\n",
       " 'c1936d515e2e41b9a3b090548bb6560e',\n",
       " '4c25faf63b31486380522e1e414844b5',\n",
       " '20116508caef4e47a92c336b7285abad',\n",
       " '4826e5d1e458496593be255bbd726d75',\n",
       " '1f87afb5316147fd812fb98bca808a26',\n",
       " '848efc47e20341b08174bee3b433c771',\n",
       " 'ea30dfe300734712b0bbd59d75f1e6dd',\n",
       " '1df9d72cd1e84a24a93e47b7f654d6fa',\n",
       " '71efd9c38ac44202810d34e7fa2bd8ea',\n",
       " '3ce20cdb0cea475aa9402bc1b225a958',\n",
       " 'a2ad35bbc2644150ab3cc2dfdf0d7191',\n",
       " '6bad13e8d223455c850e2097376862d1',\n",
       " 'eba57d282eb84cbcbfde85f9755539c4',\n",
       " '27a552bff2bd4e1da6b1d4dfd59745a0',\n",
       " 'c46bcd29940c46b2a7c80e40f3d1877f',\n",
       " '424e126f519b48c9a4c8289f4bc0b6a2',\n",
       " 'f775fbe1be7e449e899b60dff80ee3f9',\n",
       " '58f97bd76a58434ba5a28c587c1504d5',\n",
       " 'bca6ed258c7341ea8d27f6eb9f46baeb',\n",
       " '1a41991429aa4dc2800ab2dbe62024c4',\n",
       " 'b9ba4ffded414bf085c0ca6c9e4d5889',\n",
       " 'd2235496258b4a498f9ae437519c06c6',\n",
       " '93e89f9102e14bebb475365443cef59a',\n",
       " 'c3b497b4f0ef42049e649341993cae9d',\n",
       " '899285ac8c6443d2a7d83a19cfcbaf75',\n",
       " '023dc7c8f9804d9bbe9e488c7dcf0c0f',\n",
       " '86b0ed730c2c494b87a43a55355222a5',\n",
       " '42d5e2a0b7884b39ab70cc6ca311295e',\n",
       " '884d15c5f0304f44917815a034e0829c',\n",
       " '13c7a4e2771b4b84b460232a4e01531c',\n",
       " '113e40f2710a4984a7583aeb42e26d69',\n",
       " 'c2863f4014ca47cbbfd29554a7034d8f',\n",
       " '0fe6088f656447cb9bb807a539527aaf',\n",
       " '4c48d18b93fe4ea38fce99ef0bdffee7',\n",
       " 'bd609dd48156406fbc88660c7c33194c',\n",
       " '3e77342bfd244f909c356d881bceb5ca',\n",
       " 'ef0b0b370c6f4c2f840af4c11c1721c5',\n",
       " 'dc702db7029046178e0d19a3182a1e39',\n",
       " 'e132824eb1d84fecba001a5ace32cafa',\n",
       " '72699b5fe81c487aa1a58194fb8bd88d',\n",
       " '3aeca8a9a0534151abd9bb4ca3d097e5',\n",
       " '77c64204171f4f41b32118a70b5a17f0',\n",
       " '1fb09212581348c5ad3544b0881af7eb',\n",
       " 'cb37586083ef43f2b9c22573eeb5ac74',\n",
       " 'ad3afd6f904e484ea126e4f4ad1eae0a',\n",
       " '8a030aa337e742f8ae731ad521f3a9c1',\n",
       " 'ee4b14b95f94453b858bc476d200462e',\n",
       " '93d912b579a54ccfa3a239e80c890d75',\n",
       " '3601fe33ae2f4a43b26376868450776e',\n",
       " '9c41075aa6154e0b8064a7720d3e8a97',\n",
       " '484c8c76aff54a7797cbc4b789cb5303',\n",
       " '7cfabbd83dca4d0d84403b29c6084196',\n",
       " 'c46bab80589a4a90a770c1a0e085f608',\n",
       " '22064d8aa626483c843d631bcccbd355',\n",
       " 'abe58e45d0cf499f82f45ef113406f88',\n",
       " 'da193e1ff85943379c9147ce9f8db8f0',\n",
       " 'b924647ebfbf4c51939bdc46ab6fb8f9',\n",
       " '46da382b891d4435906d438c28a24f8a',\n",
       " '244f741164f949d2b8b43eab0fdc84d2',\n",
       " '83bbcc1a628748059003cd880da01e37',\n",
       " '06f83a1342f242b0ad8efda0c02d8a18',\n",
       " '73e6f2968198471b9e0df2e57f721a92']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = QdrantVectorStore(client, collection_name=\"langchain-py-rag-pt1-QA\", embedding=embeddings)\n",
    "vector_store.add_documents(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\"\n",
    "    ]\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "\n",
    "    qa_filter = {\n",
    "        \"must\": [\n",
    "            {\n",
    "                \"key\": \"metadata.section\",\n",
    "                \"match\": {\n",
    "                    \"value\": query[\"section\"],\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=qa_filter,\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'end of the post about Task Decomposition', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'start_index': 32594, 'section': 'end', '_id': '1fb09212-5813-48c5-ad35-44b0881af7eb', '_collection_name': 'langchain-py-rag-pt1-QA'}, page_content='},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'start_index': 30154, 'section': 'end', '_id': 'e132824e-b1d8-4fec-ba00-1a5ace32cafa', '_collection_name': 'langchain-py-rag-pt1-QA'}, page_content='Resources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'start_index': 33466, 'section': 'end', '_id': 'cb375860-83ef-43f2-b9c2-2573eeb5ac74', '_collection_name': 'langchain-py-rag-pt1-QA'}, page_content='}\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'), Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'start_index': 39745, 'section': 'end', '_id': 'b924647e-bfbf-4c51-939b-dc46ab6fb8f9', '_collection_name': 'langchain-py-rag-pt1-QA'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'The end of the post highlights that long-term planning and task decomposition can be challenging due to limitations in communication bandwidth and the ability to adjust plans in response to errors. It points out that large language models (LLMs) find it difficult to effectively explore the solution space and adapt, unlike humans who learn from experiences. Overall, this reflects the complexity of managing tasks over extended periods.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
